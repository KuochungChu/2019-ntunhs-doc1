{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark DataFrames & SQL - Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import pyspark\n",
    "sc = pyspark.SparkContext()\n",
    "sqlContext = pyspark.SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Build Spark DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Build Spark DataFrames from Python Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "|  A|  B|\n",
      "+---+---+\n",
      "|  1|  2|\n",
      "|  3|  4|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#data: 表示資料內容\n",
    "#schema: 表示欄位名稱\n",
    "DT1 = sqlContext.createDataFrame(data=[(1,2), (3,4)], schema=(\"A\", \"B\"))\n",
    "\n",
    "DT1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Build Spark DataFrames from RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'\"date\",\"time\",\"size\",\"r_version\",\"r_arch\",\"r_os\",\"package\",\"version\",\"country\",\"ip_id\"',\n",
       " b'\"2015-12-12\",\"13:42:10\",257886,\"3.2.2\",\"i386\",\"mingw32\",\"HistData\",\"0.7-6\",\"CZ\",1']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.textFile(\"/home/jovyan/dataset/2015-12-12.csv\", use_unicode=False).take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#將資料\"2015-12-12\",\"13:42:10\",257886,\"3.2.2\",\"i386\",\"mingw32\",\"HistData\",\"0.7-6\",\"CZ\",1 的引號拿掉\n",
    "#以,分隔資料\n",
    "dat = sc.textFile(\"/home/jovyan/dataset/2015-12-12.csv\", use_unicode=True).\\\n",
    "                    map(lambda x:x.replace('\"', \"\")).\\\n",
    "                    map(lambda x:x.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['date',\n",
       "  'time',\n",
       "  'size',\n",
       "  'r_version',\n",
       "  'r_arch',\n",
       "  'r_os',\n",
       "  'package',\n",
       "  'version',\n",
       "  'country',\n",
       "  'ip_id'],\n",
       " ['2015-12-12',\n",
       "  '13:42:10',\n",
       "  '257886',\n",
       "  '3.2.2',\n",
       "  'i386',\n",
       "  'mingw32',\n",
       "  'HistData',\n",
       "  '0.7-6',\n",
       "  'CZ',\n",
       "  '1']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[date: string, time: string, size: string, r_version: string, r_arch: string, r_os: string, package: string, version: string, country: string, ip_id: string]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DT2 = sqlContext.createDataFrame(data = dat.filter(lambda x:x[0]!='date'),\n",
    "                                 schema=dat.filter(lambda x:x[0]=='date').\\\n",
    "                                 collect()[0])\n",
    "\n",
    "DT2.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dat.filter(lambda x:x[0]!='date').take(10)\n",
    "#dat.filter(lambda x:x[0]=='date').take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(date='2015-12-12', time='13:42:10', size='257886', r_version='3.2.2', r_arch='i386', r_os='mingw32', package='HistData', version='0.7-6', country='CZ', ip_id='1'),\n",
       " Row(date='2015-12-12', time='13:24:37', size='1236751', r_version='3.2.2', r_arch='x86_64', r_os='mingw32', package='RJSONIO', version='1.3-0', country='DE', ip_id='2')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#其實內容是透過Row的方式把資料集合在一起\n",
    "DT2.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-------+---------+------+-------+---------+-------+-------+-----+\n",
      "|      date|    time|   size|r_version|r_arch|   r_os|  package|version|country|ip_id|\n",
      "+----------+--------+-------+---------+------+-------+---------+-------+-------+-----+\n",
      "|2015-12-12|13:42:10| 257886|    3.2.2|  i386|mingw32| HistData|  0.7-6|     CZ|    1|\n",
      "|2015-12-12|13:24:37|1236751|    3.2.2|x86_64|mingw32|  RJSONIO|  1.3-0|     DE|    2|\n",
      "|2015-12-12|13:42:35|2077876|    3.2.2|  i386|mingw32|   UsingR|  2.0-5|     CZ|    1|\n",
      "|2015-12-12|13:42:01| 266724|    3.2.2|  i386|mingw32|gridExtra|  2.0.0|     CZ|    1|\n",
      "|2015-12-12|13:00:21|3687766|       NA|    NA|     NA|     lme4| 1.1-10|     DE|    3|\n",
      "|2015-12-12|13:08:56|  57429|       NA|    NA|     NA| testthat| 0.11.0|     DE|    3|\n",
      "|2015-12-12|13:08:09| 216068|    3.2.2|x86_64|mingw32|  mvtnorm|  1.0-3|     DE|    4|\n",
      "|2015-12-12|13:25:00|3595497|    3.2.2|x86_64|mingw32|     maps|  3.0.1|     DE|    2|\n",
      "|2015-12-12|13:25:05|1579597|    3.2.2|x86_64|mingw32|       sp|  1.2-1|     DE|    2|\n",
      "|2015-12-12|13:25:21| 892152|    3.2.3|x86_64|mingw32|geosphere|  1.4-3|     DE|    2|\n",
      "+----------+--------+-------+---------+------+-------+---------+-------+-------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DT2.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(DT2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['date',\n",
       " 'time',\n",
       " 'size',\n",
       " 'r_version',\n",
       " 'r_arch',\n",
       " 'r_os',\n",
       " 'package',\n",
       " 'version',\n",
       " 'country',\n",
       " 'ip_id']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DT2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('date', 'string'),\n",
       " ('time', 'string'),\n",
       " ('size', 'string'),\n",
       " ('r_version', 'string'),\n",
       " ('r_arch', 'string'),\n",
       " ('r_os', 'string'),\n",
       " ('package', 'string'),\n",
       " ('version', 'string'),\n",
       " ('country', 'string'),\n",
       " ('ip_id', 'string')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DT2.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Change DataFrames Properties\n",
    "\n",
    "### 2.1 Change Column Type\n",
    "\n",
    "Availabel types include\n",
    "- BinaryType\n",
    "- BooleanType\n",
    "- ByteType\n",
    "- DoubleType\n",
    "- DateType\n",
    "- FloatType\n",
    "- IntegerType\n",
    "- etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType, DateType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 利用 withColumn 方法進行欄位修改\n",
    "DT3 = DT2.withColumn(\"size\", DT2[\"size\"].cast(IntegerType()))\n",
    "DT3 = DT3.withColumn(\"date\", DT3[\"date\"].cast(DateType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('date', 'date'),\n",
       " ('time', 'string'),\n",
       " ('size', 'int'),\n",
       " ('r_version', 'string'),\n",
       " ('r_arch', 'string'),\n",
       " ('r_os', 'string'),\n",
       " ('package', 'string'),\n",
       " ('version', 'string'),\n",
       " ('country', 'string'),\n",
       " ('ip_id', 'string')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DT3.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-------+---------+------+-------+---------+-------+-------+-----+\n",
      "|      date|    time|   size|r_version|r_arch|   r_os|  package|version|country|ip_id|\n",
      "+----------+--------+-------+---------+------+-------+---------+-------+-------+-----+\n",
      "|2015-12-12|13:42:10| 257886|    3.2.2|  i386|mingw32| HistData|  0.7-6|     CZ|    1|\n",
      "|2015-12-12|13:24:37|1236751|    3.2.2|x86_64|mingw32|  RJSONIO|  1.3-0|     DE|    2|\n",
      "|2015-12-12|13:42:35|2077876|    3.2.2|  i386|mingw32|   UsingR|  2.0-5|     CZ|    1|\n",
      "|2015-12-12|13:42:01| 266724|    3.2.2|  i386|mingw32|gridExtra|  2.0.0|     CZ|    1|\n",
      "|2015-12-12|13:00:21|3687766|       NA|    NA|     NA|     lme4| 1.1-10|     DE|    3|\n",
      "+----------+--------+-------+---------+------+-------+---------+-------+-------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DT3.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Change Column Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 利用 withColumnRenamed 方法進行欄位名稱修改\n",
    "DT4 = DT2.withColumnRenamed(\"size\", \"size_new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------+---------+------+-------+---------+-------+-------+-----+\n",
      "|      date|    time|size_new|r_version|r_arch|   r_os|  package|version|country|ip_id|\n",
      "+----------+--------+--------+---------+------+-------+---------+-------+-------+-----+\n",
      "|2015-12-12|13:42:10|  257886|    3.2.2|  i386|mingw32| HistData|  0.7-6|     CZ|    1|\n",
      "|2015-12-12|13:24:37| 1236751|    3.2.2|x86_64|mingw32|  RJSONIO|  1.3-0|     DE|    2|\n",
      "|2015-12-12|13:42:35| 2077876|    3.2.2|  i386|mingw32|   UsingR|  2.0-5|     CZ|    1|\n",
      "|2015-12-12|13:42:01|  266724|    3.2.2|  i386|mingw32|gridExtra|  2.0.0|     CZ|    1|\n",
      "|2015-12-12|13:00:21| 3687766|       NA|    NA|     NA|     lme4| 1.1-10|     DE|    3|\n",
      "+----------+--------+--------+---------+------+-------+---------+-------+-------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DT4.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Order DataFrame by Specified Column(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+----+---------+------+----+-----------+-------+-------+-----+\n",
      "|      date|    time|size|r_version|r_arch|r_os|    package|version|country|ip_id|\n",
      "+----------+--------+----+---------+------+----+-----------+-------+-------+-----+\n",
      "|2015-12-12|20:20:28| 504|       NA|    NA|  NA|  orloca.es|    3.2|     CN| 2365|\n",
      "|2015-12-12|20:17:22| 504|       NA|    NA|  NA|  financial|    0.1|     CN| 7321|\n",
      "|2015-12-12|20:20:58| 504|       NA|    NA|  NA|poistweedie|    1.0|     CN|   74|\n",
      "|2015-12-12|19:06:56| 504|       NA|    NA|  NA|httpRequest|  0.0.5|     CN| 1133|\n",
      "|2015-12-12|19:09:58| 504|       NA|    NA|  NA|    polycor|  0.7-0|     CN| 1153|\n",
      "|2015-12-12|20:34:41| 504|       NA|    NA|  NA|     merror|    1.0|     CN| 5337|\n",
      "|2015-12-12|20:38:03| 504|       NA|    NA|  NA|    sddpack|    0.9|     CN|13071|\n",
      "|2015-12-12|20:36:24| 504|       NA|    NA|  NA|      pheno|    1.5|     CN| 4943|\n",
      "|2015-12-12|20:48:58| 504|       NA|    NA|  NA|    divagis|  1.0.0|     CN| 4901|\n",
      "|2015-12-12|20:12:51| 504|       NA|    NA|  NA|     Oarray|  1.4-2|     CN|16796|\n",
      "+----------+--------+----+---------+------+----+-----------+-------+-------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#由小到大\n",
    "DT3.sort(DT3.size.asc()).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------+---------+------+------------+--------------------+-------+-------+-----+\n",
      "|      date|    time|    size|r_version|r_arch|        r_os|             package|version|country|ip_id|\n",
      "+----------+--------+--------+---------+------+------------+--------------------+-------+-------+-----+\n",
      "|2015-12-12|02:27:31|68736865|    3.2.3|x86_64|     mingw32|           TCGA2STAT|    1.2|     US| 2700|\n",
      "|2015-12-12|01:31:52|68736865|    3.1.3|x86_64|darwin10.8.0|           TCGA2STAT|    1.2|     US| 2700|\n",
      "|2015-12-12|02:28:49|68736865|    3.3.0|x86_64|   linux-gnu|           TCGA2STAT|    1.2|     US| 2700|\n",
      "|2015-12-12|02:28:30|68736865|    3.2.3|x86_64|     mingw32|           TCGA2STAT|    1.2|     US| 2700|\n",
      "|2015-12-12|21:23:23|68736862|    3.2.3|x86_64|darwin13.4.0|           TCGA2STAT|    1.2|     US| 2700|\n",
      "|2015-12-12|02:19:32|68736862|    3.2.0|  i386|     mingw32|           TCGA2STAT|    1.2|     US| 2700|\n",
      "|2015-12-12|13:17:41|68736856|    3.2.3|x86_64|   linux-gnu|           TCGA2STAT|    1.2|     GB|  548|\n",
      "|2015-12-12|01:28:03|68736856|    3.2.3|x86_64|     mingw32|           TCGA2STAT|    1.2|     US| 2700|\n",
      "|2015-12-12|17:06:20|68736856|       NA|    NA|          NA|           TCGA2STAT|    1.2|     US| 3084|\n",
      "|2015-12-12|01:41:08|62559786|       NA|    NA|          NA|ChemometricsWithR...|  0.1.3|     US| 7666|\n",
      "+----------+--------+--------+---------+------+------------+--------------------+-------+-------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#由大到小\n",
    "DT3.sort(DT3.size.desc()).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Filtering, and Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11161009458040756"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#針對size小於1000的資料查詢\n",
    "DT3.filter(DT3['size'] <1000).count() / DT3.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.009273193054466087"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DT3.filter(DT3['package'] == \"ggplot2\").count() / DT3.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|     package|count|\n",
      "+------------+-----+\n",
      "|        Rcpp| 4783|\n",
      "|     ggplot2| 3913|\n",
      "|     stringi| 3748|\n",
      "|     stringr| 3449|\n",
      "|        plyr| 3436|\n",
      "|    magrittr| 3265|\n",
      "|      digest| 3223|\n",
      "|    reshape2| 3205|\n",
      "|RColorBrewer| 3046|\n",
      "|      scales| 3007|\n",
      "+------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#合併後的值再由大到小排序\n",
    "DT3.groupBy(\"package\").count().sort(\"count\", ascending = False).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#同上\n",
    "package_count = DT3.groupBy(\"package\").count().sort(\"count\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|     package|count|\n",
      "+------------+-----+\n",
      "|        Rcpp| 4783|\n",
      "|     ggplot2| 3913|\n",
      "|     stringi| 3748|\n",
      "|     stringr| 3449|\n",
      "|        plyr| 3436|\n",
      "|    magrittr| 3265|\n",
      "|      digest| 3223|\n",
      "|    reshape2| 3205|\n",
      "|RColorBrewer| 3046|\n",
      "|      scales| 3007|\n",
      "+------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "package_count.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Transform A DataFrame Column (using UDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+------+\n",
      "|     package|count|  perc|\n",
      "+------------+-----+------+\n",
      "|        Rcpp| 4783|1.133%|\n",
      "|     ggplot2| 3913|0.927%|\n",
      "|     stringi| 3748|0.888%|\n",
      "|     stringr| 3449|0.817%|\n",
      "|        plyr| 3436|0.814%|\n",
      "|    magrittr| 3265|0.774%|\n",
      "|      digest| 3223|0.764%|\n",
      "|    reshape2| 3205| 0.76%|\n",
      "|RColorBrewer| 3046|0.722%|\n",
      "|      scales| 3007|0.713%|\n",
      "+------------+-----+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#建立一個客製化SQL函數(user define function)\n",
    "#回傳四捨五入後的值，例如: round(80.23456, 2) :  80.23\n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "derive_perc = udf(lambda x: str(round(x * 100, 3)) + \"%\")\n",
    "# or \n",
    "# @udf\n",
    "# def derive_perc(x):\n",
    "#     return(str(round(x * 100, 3)) + \"%\")\n",
    "\n",
    "#透過withColumn調用udf函數\n",
    "package_count = package_count.withColumn(\"perc\", derive_perc(package_count['count'] / DT3.count()))\n",
    "\n",
    "package_count.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+------+\n",
      "|package|count|  perc|\n",
      "+-------+-----+------+\n",
      "|     DT|   97|0.023%|\n",
      "+-------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "package_count.filter(package_count.package == 'DT').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Using Spark SQL\n",
    "* 另外一種方式進行資料查詢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#建立一個暫時性的view針對dataframe\n",
    "#這個暫時性的view的生命週期僅限於SparkSession之內\n",
    "#目標是這個dataframe=>package_count\n",
    "\n",
    "package_count.createOrReplaceTempView(\"package_count_sql_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(package_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+------+\n",
      "|package|count|  perc|\n",
      "+-------+-----+------+\n",
      "|   Rcpp| 4783|1.133%|\n",
      "|ggplot2| 3913|0.927%|\n",
      "+-------+-----+------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "package_count.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第一個簡單的SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(perc='0.023%')]\n"
     ]
    }
   ],
   "source": [
    "query_result = sqlContext.sql(\"select perc \\\n",
    "                               from package_count_sql_table \\\n",
    "                               where package = 'DT'\")\n",
    "\n",
    "print(query_result.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第二個簡單的SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+------+\n",
      "|package|count|  perc|\n",
      "+-------+-----+------+\n",
      "|   slam| 1006|0.238%|\n",
      "|     sp| 1020|0.242%|\n",
      "|  shiny| 1041|0.247%|\n",
      "|  tidyr| 1042|0.247%|\n",
      "|plotrix| 1066|0.253%|\n",
      "+-------+-----+------+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "query_result = sqlContext.sql(\"select * \\\n",
    "                                from package_count_sql_table \\\n",
    "                                where count > 1000 \\\n",
    "                                order by count asc\")\n",
    "print(query_result.show(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 別忘記了，查詢回來的結果，也可以透過 RDD 方式運算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['slam:0.238%',\n",
       " 'sp:0.242%',\n",
       " 'shiny:0.247%',\n",
       " 'tidyr:0.247%',\n",
       " 'plotrix:0.253%',\n",
       " 'wordcloud:0.254%',\n",
       " 'rgl:0.257%',\n",
       " 'markdown:0.261%',\n",
       " 'irlba:0.27%',\n",
       " 'pkgmaker:0.27%']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_result.rdd.map(lambda x:x['package'] + \":\" + x['perc']).take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
